[
  {
    "objectID": "src/technical_skills.html",
    "href": "src/technical_skills.html",
    "title": "Technical Skills",
    "section": "",
    "text": "Proficiencies\nPython:\nMatplotlib\n\nNumPy\n\nPandas\n\nSeaborn\n\nSciPy\n\nSciKit-Learn\nSQL\nFlask\nPowerBI\nTableau\nC++"
  },
  {
    "objectID": "src/projects.html",
    "href": "src/projects.html",
    "title": "Projects",
    "section": "",
    "text": "Assisted Reproductive Technology (ART) regression analysis and user application"
  },
  {
    "objectID": "src/education.html",
    "href": "src/education.html",
    "title": "Education",
    "section": "",
    "text": "AS: Criminal Justice\nBS: Exercise Science, Health Sciences\nBS: Applied Computer Science, concentration on Data Science (May 2026)\nCertifications:\nBLS\nACLS"
  },
  {
    "objectID": "src/blog.html",
    "href": "src/blog.html",
    "title": "Week 1:",
    "section": "",
    "text": "Assisted Reproductive Technology (ART) regression analysis and user application blog:\n\nWeek 1:\nThis first week was the initial planning stage outlining the subject matter of the project and what I want the end product to show in terms of skill and exploration.\n\n\nWeek 2:\nWhat did you do last week?\nLast week I explored the direction I plan to go with my project, specifically creating a rough timeline and achievable goals. I’m still homing in on what is achievable with a wants v. needs type of approach. I plan to create a predictive model starting with one feature then expanding it. My priority is the backend workings of the model then linking it to a simple frontend design\nWhat do you plan to do this week?\nThis week I plan to setup my website and do more research on applicable techniques as well as review my dataset and transforming it into usable information\nAre there any impediments in your way?\nJust myself, after a long break and this being my final semester it’s been a slower ramp up than in the past but I’m simply focusing on doing one thing at a time. The short week and crazy snow storm had my week not really matching up with course schedules.\nReflection on the process you used last week, how can you make the process work better?\nThere wasn’t much of a structured process last week, it was more so just doing some thinking and cursory google searches. I’m creating a little checklist of tasks this week to ramp back up into an efficient working setup.\n\n\nWeek 3:\nWhat did you do last week?\nI completed the project proposal rough draft and decided on the specific frameworks I’ll be using for each person. I will be primarily using Flask, Python based modules, and SQLite. I did some preliminary data cleaning and identified the attributes with the best backing data.\nWhat do you plan to do this week?\nThis week I plan to do some initial data transformation and exploration just to get in the flow of building this project. Additionally, I plan to set up my frontend Flask template to start a front-to-back approach to the application. I also plan to format my site.\nAre there any impediments in your way?\nNot particularly, time mostly. I think continuing to work on the steps I identified in the initial planning stage will help build momentum.\nReflection on the process you used last week, how can you make the process work better?\nI spent a little too much time in the contemplation stage last week and this week I plan to take more action. Putting together the rough version of my frontend will motivate me to work on it once I see how ugly it is initially. Time is always a factor but I have put together a work/rest schedule for myself this weekend.\n\n\nWeek 4:\nWhat did you do last week?\nLast week I finished the project proposals and reviewed the feedback I received to better home in on my project. Additionally, I began laying the foundation for the UI and some data preprocessing.\nWhat do you plan to do this week?\nThis week I implemented a login page and database for users as well as laying the ground-work for my users attributes database. I used Flask for the front-end and SQLite for the database. I initially wrote the front-end in with simple logic and template rendering with placeholder names. Additionally, I got some free templates online and started to plug them in to my existing code.\nAre there any impediments in your way?\nThis was a weird week and I was working without internet access for most of it which made some of the issues I ran into harder to solve. The upcoming week will be much more productive\nReflection on the process you used last week, how can you make the process work better?\nMy process last week was to simply do what I could given the circumstances. Next week should be much more normal and will allow me to utilize available resources much better. My small issues were solved by looking at previous code bases on my machine.\n\n\nWeek 5:\nWhat did you do last week?\nI implemented a login page with a connected local database for simple login querying. As it is low on my priority list it’s moreso the minimal needed to make the app work. I’m currently using a plan of creating a prototype app from front to back, then developing in a greater scope from back to front.\nWhat do you plan to do this week?\nThis week I need to focus on getting my website up and running, but this weekend I plan to do some heavy lifting on the dashboard and linking my analytical code to one or more features in the dashboard. Users entering values then getting a return value from my code for a single feature would be the benchmark by the end of the week.\nAre there any impediments in your way?\nNo, considering last week wasn’t as productive as I would have liked I have allocated more time to schoolwork this week. I have clear vision of what I want the application to look like by the end of the week and have drawn out a roadmap with bullet points of what I need for each benchmark.\nReflection on the process last week and how can I make it better?\nLast week my process wasn’t structured enough. This week I have a distinct plan both in my time and a roadmap for what I want accomplished and how I will do it.\n\n\nWeek 6:\n\n\nWeek 7:\n\n\nWeek 8:\n\n\nWeek 9:\n\n\nWeek 10:\n\n\nWeek 11:"
  },
  {
    "objectID": "ART/ProjectDataDiscovery.html",
    "href": "ART/ProjectDataDiscovery.html",
    "title": "Portfolio: Joseph Hook",
    "section": "",
    "text": "print(success_20['LocationAbbr'].nunique())\nprint(success_21['LocationAbbr'].nunique())\nprint(success_22['LocationAbbr'].nunique())\nprint(filtered_summary_success_20['LocationAbbr'].nunique())\nprint(filtered_summary_success_21['LocationAbbr'].nunique())\nprint(filtered_summary_success_22['LocationAbbr'].nunique())\n\n50\n47\n43\n40\n44\n36\n\n\n\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nregion_map = {'CT' : 'NorthEast', 'ME' : 'NorthEast', 'MA' : 'NorthEast', 'NH' : 'NorthEast', 'RI' : 'NorthEast', 'VT' : 'NorthEast', 'NJ' : 'NorthEast', 'NY' : 'NorthEast', 'PA' : 'NorthEast',\n              \n              'IL' : 'MidWest', 'IN' : 'MidWest', 'MI' : 'MidWest', 'OH' : 'MidWest', 'WI' : 'MidWest', 'IA' : 'MidWest', 'KS' : 'MidWest', 'MN': 'MidWest', 'MO' : 'MidWest', 'NE' : 'MidWest',\n              'ND': 'MidWest', 'SD' : 'MidWest',\n              \n              'DE' : 'South', 'DC' : 'South', 'FL' : 'South', 'GA' : 'South', 'MD' : 'South', 'NC' : 'South', 'SC' : 'South', 'VA' : 'South', 'WV': 'South', 'AL' : 'South', 'KY' : 'South', 'MS' : 'South',\n              'TN' : 'South', 'AR' : 'South', 'LA' : 'South', 'OK' : 'South', 'TX' : 'South',\n              \n              'AZ' : 'West', 'CO' : 'West', 'ID' : 'West', 'MT' : 'West', 'NV' : 'West', 'NM' : 'West', 'UT' : 'West', 'WY' : 'West', 'AK' : 'West', 'CA' : 'West', 'HI': 'West', 'OR' : 'West', 'WA' : 'West' }\n\n\nsuccess_20 = pd.read_csv('2020SuccessRates.csv')\nprofile_20 = pd.read_csv('2020Profiles.csv')\ncycle_20 = pd.read_csv('2020ARTCycles.csv')\n\nsuccess_21 = pd.read_csv('2021SuccessRates.csv')\nprofile_21 = pd.read_csv('2021Profiles.csv')\ncycle_21 = pd.read_csv('2021Cycles.csv')\n\nsuccess_22 = pd.read_csv('2022SuccessRates.csv')\nprofile_22 = pd.read_csv('2022Profiles.csv')\ncycle_22 = pd.read_csv('2022Cycles.csv')\n\n\nfiltered_summary_success_20 = success_20[success_20['Data_Value_Footnote'].isna() | (success_20['Data_Value_Footnote'] == '')]\nsummary_success_20 = filtered_summary_success_20.groupby('LocationAbbr')['Data_Value_num'].mean().reset_index()\nsummary_success_20 = summary_success_20.sort_values(by='LocationAbbr').reset_index(drop = 'True')\n\n\nfiltered_summary_success_21 = success_21[success_21['Data_Value_Footnote'].isna() | (success_21['Data_Value_Footnote'] == '')]\nsummary_success_21 = filtered_summary_success_21.groupby('LocationAbbr')['Data_Value_num'].mean().reset_index()\nsummary_success_21 = summary_success_21.sort_values(by='LocationAbbr').reset_index(drop = 'True')\n\n\nfiltered_summary_success_22 = success_22[success_22['Data_Value_Footnote'].isna() | (success_22['Data_Value_Footnote'] == '')]\nsummary_success_22 = filtered_summary_success_22.groupby('LocationAbbr')['Data_Value_num'].mean().reset_index()\nsummary_success_22 = summary_success_22.sort_values(by='LocationAbbr').reset_index(drop = 'True')\n\n\ncounts_per_state_20 = filtered_summary_success_20.groupby('LocationAbbr')['Data_Value_num'].count().reset_index(name = 'Count')\ncounts_per_state_21 = filtered_summary_success_21.groupby('LocationAbbr')['Data_Value_num'].count().reset_index(name = 'Count')\ncounts_per_state_22 = filtered_summary_success_22.groupby('LocationAbbr')['Data_Value_num'].count().reset_index(name = 'Count')\n\nstates_over_10_20 = counts_per_state_20[counts_per_state_20['Count'] &gt; 10]['LocationAbbr']\nstates_over_10_21 = counts_per_state_21[counts_per_state_21['Count'] &gt; 10]['LocationAbbr']\nstates_over_10_22 = counts_per_state_22[counts_per_state_22['Count'] &gt; 10]['LocationAbbr']\n\n\nfiltered_over_10_20 = summary_success_20[summary_success_20['LocationAbbr'].isin(states_over_10_20)].reset_index()\nfiltered_over_10_21 = summary_success_21[summary_success_21['LocationAbbr'].isin(states_over_10_21)].reset_index()\nfiltered_over_10_22 = summary_success_22[summary_success_22['LocationAbbr'].isin(states_over_10_22)].reset_index()\n\nfiltered_over_10_20['Region'] = filtered_over_10_20['LocationAbbr'].map(region_map)\nfiltered_over_10_21['Region'] = filtered_over_10_21['LocationAbbr'].map(region_map)\nfiltered_over_10_22['Region'] = filtered_over_10_22['LocationAbbr'].map(region_map)\n\nsummary_region_20 = filtered_over_10_20.groupby('Region')['Data_Value_num'].mean().reset_index()\nsummary_region_21 = filtered_over_10_21.groupby('Region')['Data_Value_num'].mean().reset_index()\nsummary_region_22 = filtered_over_10_22.groupby('Region')['Data_Value_num'].mean().reset_index()\n\nsummary_region_20[\"Year\"] = 2020 \nsummary_region_21[\"Year\"] = 2021\nsummary_region_22[\"Year\"] = 2022\n\nregion_combined = pd.concat([summary_region_20, summary_region_21, summary_region_22], ignore_index = True)\nsummary_region_yr = region_combined.groupby(['Region', 'Year'])['Data_Value_num'].mean().reset_index()\n\n\n\n\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[78], line 17\n      4 import matplotlib.pyplot as plt\n      6 region_map = {'CT' : 'NorthEast', 'ME' : 'NorthEast', 'MA' : 'NorthEast', 'NH' : 'NorthEast', 'RI' : 'NorthEast', 'VT' : 'NorthEast', 'NJ' : 'NorthEast', 'NY' : 'NorthEast', 'PA' : 'NorthEast',\n      7               \n      8               'IL' : 'MidWest', 'IN' : 'MidWest', 'MI' : 'MidWest', 'OH' : 'MidWest', 'WI' : 'MidWest', 'IA' : 'MidWest', 'KS' : 'MidWest', 'MN': 'MidWest', 'MO' : 'MidWest', 'NE' : 'MidWest',\n   (...)\n     13               \n     14               'AZ' : 'West', 'CO' : 'West', 'ID' : 'West', 'MT' : 'West', 'NV' : 'West', 'NM' : 'West', 'UT' : 'West', 'WY' : 'West', 'AK' : 'West', 'CA' : 'West', 'HI': 'West', 'OR' : 'West', 'WA' : 'West' }\n---&gt; 17 success_20 = pd.read_csv('2020SuccessRates.csv')\n     18 profile_20 = pd.read_csv('2020Profiles.csv')\n     19 cycle_20 = pd.read_csv('2020ARTCycles.csv')\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n    899 kwds_defaults = _refine_defaults_read(\n    900     dialect,\n    901     delimiter,\n   (...)\n    908     dtype_backend=dtype_backend,\n    909 )\n    910 kwds.update(kwds_defaults)\n--&gt; 912 return _read(filepath_or_buffer, kwds)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577, in _read(filepath_or_buffer, kwds)\n    574 _validate_names(kwds.get(\"names\", None))\n    576 # Create the parser.\n--&gt; 577 parser = TextFileReader(filepath_or_buffer, **kwds)\n    579 if chunksize or iterator:\n    580     return parser\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407, in TextFileReader.__init__(self, f, engine, **kwds)\n   1404     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1406 self.handles: IOHandles | None = None\n-&gt; 1407 self._engine = self._make_engine(f, self.engine)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661, in TextFileReader._make_engine(self, f, engine)\n   1659     if \"b\" not in mode:\n   1660         mode += \"b\"\n-&gt; 1661 self.handles = get_handle(\n   1662     f,\n   1663     mode,\n   1664     encoding=self.options.get(\"encoding\", None),\n   1665     compression=self.options.get(\"compression\", None),\n   1666     memory_map=self.options.get(\"memory_map\", False),\n   1667     is_text=is_text,\n   1668     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1669     storage_options=self.options.get(\"storage_options\", None),\n   1670 )\n   1671 assert self.handles is not None\n   1672 f = self.handles.handle\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/common.py:859, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    854 elif isinstance(handle, str):\n    855     # Check whether the filename is to be opened in binary mode.\n    856     # Binary mode does not support 'encoding' and 'newline'.\n    857     if ioargs.encoding and \"b\" not in ioargs.mode:\n    858         # Encoding\n--&gt; 859         handle = open(\n    860             handle,\n    861             ioargs.mode,\n    862             encoding=ioargs.encoding,\n    863             errors=errors,\n    864             newline=\"\",\n    865         )\n    866     else:\n    867         # Binary mode\n    868         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: '2020SuccessRates.csv'\n\n\n\n\nplt.figure(figsize=(10, 6))\nsns.lineplot(data = summary_region_yr, x = 'Year', y = 'Data_Value_num', hue = 'Region')\nplt.title('Mean ART Success Rate by Region (2020-2022)')\nplt.ylabel('Mean Success Rate')\nplt.xticks([2020, 2021, 2022])\nplt.legend(title = 'Region')\nplt.show()\n\n\n\n\n\n\n\n\n\nregion_order = sorted(summary_region_20['Region'].unique())\nplt.figure(figsize=(18, 6))\nsns.barplot(data = summary_region_20, x = 'Region', y = 'Data_Value_num', order = region_order)\nplt.title('Distribution of success percentage by Region 2020')\nplt.xlabel('Region')\nplt.ylabel('Mean Success Percentage')\nplt.savefig('reg_suc_20.pdf', bbox_inches = 'tight')\nplt.show()\nplt.figure(figsize=(18, 6))\nsns.barplot(data = summary_region_21, x = 'Region', y = 'Data_Value_num', order = region_order)\nplt.title('Distribution of success percentage by Region 2021')\nplt.xlabel('Region')\nplt.ylabel('Mean Success Percentage')\nplt.savefig('reg_suc_21.pdf', bbox_inches = 'tight')\nplt.show()\nplt.figure(figsize=(18, 6))\nsns.barplot(data = summary_region_22, x = 'Region', y = 'Data_Value_num', order = region_order)\nplt.title('Distribution of success percentage by Region 2022')\nplt.xlabel('Region')\nplt.ylabel('Mean Success Percentage')\nplt.savefig('reg_suc_22.pdf', bbox_inches = 'tight')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(18, 6))\nsns.barplot(data = filtered_over_10_20, x = 'LocationAbbr', y = 'Data_Value_num', color = 'skyblue')\nplt.title('Distribution of success percentage by State 2020')\nplt.xlabel('State Abbreviation')\nplt.ylabel('Mean Success Percentage')\nplt.savefig\nplt.show()\n\nplt.figure(figsize=(18, 6))\nsns.barplot(data = filtered_over_10_21, x = 'LocationAbbr', y = 'Data_Value_num', color = 'skyblue')\nplt.title('Distirbution of success percentage by State 2021')\nplt.xlabel('State Abbreviation')\nplt.ylabel('Mean Success Percentage')\nplt.show()\n\nplt.figure(figsize=(18, 6))\nsns.barplot(data = filtered_over_10_22, x = 'LocationAbbr', y = 'Data_Value_num', color = 'skyblue')\nplt.title('Distirbution of success percentage by State 2022')\nplt.xlabel('State Abbreviation')\nplt.ylabel('Mean Success Percentage')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntype_2020 = success_20['Type'].unique()\n\nfiltered_20_type = success_20[success_20['Data_Value_Footnote'].isna() | (success_20['Data_Value_Footnote'] == '')]\nfiltered_20_type = filtered_20_type.groupby(['Type'])['Data_Value_num'].mean().reset_index()\nfiltered_20_type['Year'] = 2020\n\nfiltered_21_type = success_21[success_21['Data_Value_Footnote'].isna() | (success_21['Data_Value_Footnote'] == '')]\nfiltered_21_type = filtered_21_type.groupby(['Type'])['Data_Value_num'].mean().reset_index()\nfiltered_21_type['Year'] = 2021\n\n\nfiltered_22_type = success_22[success_22['Data_Value_Footnote'].isna() | (success_22['Data_Value_Footnote'] == '')]\nfiltered_22_type = filtered_22_type.groupby(['Type'])['Data_Value_num'].mean().reset_index()\nfiltered_22_type['Year'] = 2022\n\nsummary_type = pd.concat([filtered_20_type, filtered_21_type, filtered_22_type], ignore_index= True)\nsummary_type = summary_type[summary_type['Data_Value_num'].notna()]\n\n\nprint(type_2020)\n\n['Patients using donor eggs/embryos'\n 'Patients with no prior ART using their own eggs'\n 'Patients using their own eggs']\n\n\n\nplt.figure(figsize = (10, 6))\nsns.barplot(data = summary_type, x = 'Year', y = 'Data_Value_num', hue ='Type')\nplt.title('Mean ART Success Rate by Type and Year')\nplt.ylabel('Mean Success Rate')\nplt.xlabel('Year')\nplt.legend(title = 'Type')\nplt.show()\n\n\n\n\n\n\n\n\n\ncycle_20[\"Question\"].unique()\n\narray(['What percentage of transfers used a gestational carrier?',\n       'What were the reasons patients used ART?',\n       'What were the ages of patients who used ART?',\n       'What percentage of transfers used frozen embryos?',\n       'What percentage of cycles were discontinued after retrieval and before transfer or banking?',\n       'What was the percentage of cycles in which patients used donor eggs or embryos?',\n       'What was the percentage of cycles used for fertility preservation?',\n       'What was the average number of embryos transferred?',\n       'What percentage of transfers used intracytoplasmic sperm injection (ICSI)?',\n       'What was the percentage of cycles discontinued before an egg or embryo was transferred or banked?',\n       'What percentage of egg retrieval cycles were discontinued without any eggs retrieved?',\n       'What was the percentage of cycles in which patients used their own eggs and embryos?',\n       'What percentage of embryo transfers used a single embryo?',\n       'What percentage of transfers used preimplantation genetic testing (PGT)?'],\n      dtype=object)\n\n\n\nfac_name = cycle_20.loc[cycle_20[\"ClinicId\"] == 37, 'FacilityName'].values[0]\nprint(fac_name)\nfac_name_2 = success_20.loc[success_20[\"ClinicId\"] == 37, 'FacilityName'].values[0]\nprint(fac_name_2 == fac_name)\n\ndef clinics(df1, df2, id_col = 'ClinicId', name_col='FacilityName'):\n    #merge\n    merged = df1[[id_col, name_col]].merge(df2[[id_col, name_col]], on = id_col, suffixes = ('_df1', '_df2'), how = 'inner')\n    mismatches = merged[merged[f'{name_col}_df1'] != merged[f'{name_col}_df2']]\n    if mismatches.empty:\n        print('All clinic IDS match')\n    else:\n        print('Mismatches')\n        print(len(mismatches))\n    return\nclinics(cycle_20, success_20)\nclinics(cycle_21, success_21)\nclinics(cycle_22, success_22)\n\nMid-Iowa Fertility, PC\nTrue\nAll clinic IDS match\nAll clinic IDS match\nAll clinic IDS match\n\n\n\nprint(filtered_summary_success_20.columns)\n\nIndex(['Year', 'LocationAbbr', 'LocationDesc', 'FacilityName',\n       'MedicalDirector', 'Address', 'City', 'ZipCode', 'Phone',\n       'Clinic Status', 'Type', 'Topic', 'Question', 'Filter',\n       'Breakout_Category', 'Breakout', 'Data_Value', 'Data_Value_num',\n       'Data_Value_Footnote_Symbol', 'Data_Value_Footnote', 'Cycle_Count',\n       'ClinicId', 'TypeId', 'TopicId', 'QuestionId', 'FilterId',\n       'BreakOutCategoryId', 'BreakOutId', 'GeoLocation'],\n      dtype='object')\n\n\n\nsuccess_22['Question'].unique()\n\narray(['What percentage of embryo transfers resulted in live-birth deliveries?',\n       'What was the average number of intended egg retrievals per live-birth delivery?',\n       'What percentage of transfers resulted in singleton live-birth deliveries?',\n       'What percentage of transfers resulted in single, term, normal weight live-birth deliveries?',\n       'What percentage of embryo transfers resulted in multiple live-birth deliveries?',\n       'What percentage of intended egg retrievals resulted in singleton live-birth deliveries?',\n       'What percentage of new patients had live-birth deliveries after 1 intended egg retrieval?',\n       'What percentage of new patients had live-birth deliveries after 1 or 2 intended egg retrievals?',\n       'What percentage of intended egg retrievals resulted in single, term, normal weight live-birth deliveries?',\n       'What percentage of transfers resulted in multiple live-birth deliveries?',\n       'What percentage of new patients had live-birth deliveries after all intended egg retrievals?',\n       'What was the average number of transfers per intended egg retrieval?',\n       'What was the average number of intended egg retrievals per new patient?',\n       'What percentage of actual egg retrievals resulted in singleton live-birth deliveries?',\n       'What percentage of actual egg retrievals resulted in single, term, normal weight live-birth deliveries?',\n       'What percentage of intended egg retrievals resulted in live-birth deliveries?'],\n      dtype=object)\n\n\n\nexcluded = ['What was the average number of transfers per intended egg retrieval?', \n            'What was the average number of intended egg retrievals per new patient?']           \n\n\nsuccess_20_QF = filtered_summary_success_20[~filtered_summary_success_20[\"Question\"].isin(excluded)].copy()\nsuccess_20_QF['Expected # Cycles'] = 1/(success_20_QF['Data_Value_num']/100)\n\nsuccess_21_QF = filtered_summary_success_21[~filtered_summary_success_21[\"Question\"].isin(excluded)].copy()\nsuccess_21_QF['Expected # Cycles'] = 1/(success_21_QF['Data_Value_num']/100)\n\nsuccess_22_QF = filtered_summary_success_22[~filtered_summary_success_22[\"Question\"].isin(excluded)].copy()\nsuccess_22_QF['Expected # Cycles'] = 1/(success_22_QF['Data_Value_num']/100)\n\n\nclean_20 = success_20_QF[\n    success_20_QF['Expected # Cycles'].notna() &\n    ~success_20_QF['Expected # Cycles'].isin([-np.inf, np.inf])\n]\nclean_21 = success_21_QF[\n    success_21_QF['Expected # Cycles'].notna() &\n    ~success_21_QF['Expected # Cycles'].isin([-np.inf, np.inf])]\nclean_22 = success_22_QF[\n    success_22_QF['Expected # Cycles'].notna() &\n    ~success_22_QF['Expected # Cycles'].isin([-np.inf, np.inf])\n]\n\n\ntop_10_exp_20 = clean_20.nsmallest(10, 'Expected # Cycles')\n\n\ntop_10_exp_21 = clean_21.nsmallest(10, 'Expected # Cycles')\n\n\ntop_10_exp_22 = clean_22.nsmallest(10, 'Expected # Cycles')\n\n\nprint(clean_20['Expected # Cycles'].mean())\n\n8.537389136004697\n\n\n\nprint(clean_21['Expected # Cycles'].mean())\n\n11.86647501634556\n\n\n\nprint(clean_22['Expected # Cycles'].mean())\n\n8.748431370770913\n\n\n\ntop_10_exp_22.iloc[0,10:19]\n\nType                                          Patients using donor eggs/embryos\nTopic                                  Success Rates: Patients Using Donor Eggs\nQuestion                      What percentage of embryo transfers resulted i...\nFilter                                                                No filter\nBreakout_Category                                               Egg/embryo type\nBreakout                                                         Frozen Embryos\nData_Value                                                                 95.7\nData_Value_num                                                             95.7\nData_Value_Footnote_Symbol                                                  NaN\nName: 2979, dtype: object\n\n\n\ntop_10_exp_21.iloc[0,10:19]\n\nType                            Patients with no prior ART using their own eggs\nTopic                                    Success Rates: Patients Using Own Eggs\nQuestion                      What percentage of new patients had live-birth...\nFilter                                                    Ovulatory dysfunction\nBreakout_Category                                                Age of Patient\nBreakout                                                                    &lt;35\nData_Value                                                                 93.0\nData_Value_num                                                             93.0\nData_Value_Footnote_Symbol                                                  NaN\nName: 51932, dtype: object\n\n\n\ntop_10_exp_20.iloc[0,10:19]\n\nType                                          Patients using donor eggs/embryos\nTopic                                  Success Rates: Patients Using Donor Eggs\nQuestion                      What percentage of embryo transfers resulted i...\nFilter                                                                No filter\nBreakout_Category                                               Egg/embryo type\nBreakout                                               Fresh embryos fresh eggs\nData_Value                                                                 95.2\nData_Value_num                                                             95.2\nData_Value_Footnote_Symbol                                                  NaN\nName: 14994, dtype: object\n\n\n\nprint(top_10_exp_20['ClinicId'])\n\n14994    300.0\n7265     300.0\n12958    300.0\n12752    300.0\n12700    255.0\n13782    300.0\n16176    255.0\n13679    300.0\n36053    491.0\n35954     50.0\nName: ClinicId, dtype: float64\n\n\n\nprint(top_10_exp_20['Breakout'])\n\n14994     Fresh embryos fresh eggs\n7265      Fresh embryos fresh eggs\n12958     Fresh embryos fresh eggs\n12752     Fresh embryos fresh eggs\n12700    Fresh embryos frozen eggs\n13782     Fresh embryos fresh eggs\n16176    Fresh embryos frozen eggs\n13679     Fresh embryos fresh eggs\n36053    Fresh embryos frozen eggs\n35954    Fresh embryos frozen eggs\nName: Breakout, dtype: object\n\n\n\nprint(top_10_exp_21['Breakout'])\n\n51932    &lt;35\n54440    &lt;35\n54888    &lt;35\n57111    &lt;35\n59590    &lt;35\n54008    &lt;35\n58797    &lt;35\n59709    &lt;35\n31781    &lt;35\n39719    &lt;35\nName: Breakout, dtype: object\n\n\n\nprint(top_10_exp_22['Breakout'])\n\n2979               Frozen Embryos\n2974               Frozen Embryos\n16477    Fresh Embryos Fresh Eggs\n3015               Frozen Embryos\n16482    Fresh Embryos Fresh Eggs\n3010               Frozen Embryos\n16513    Fresh Embryos Fresh Eggs\n16518    Fresh Embryos Fresh Eggs\n7967               Frozen Embryos\n33694              Frozen Embryos\nName: Breakout, dtype: object\n\n\n\nprint(top_10_exp_20['Type'])\n\n14994    Patients using donor eggs/embryos\n7265     Patients using donor eggs/embryos\n12958    Patients using donor eggs/embryos\n12752    Patients using donor eggs/embryos\n12700    Patients using donor eggs/embryos\n13782    Patients using donor eggs/embryos\n16176    Patients using donor eggs/embryos\n13679    Patients using donor eggs/embryos\n36053    Patients using donor eggs/embryos\n35954    Patients using donor eggs/embryos\nName: Type, dtype: object\n\n\n\nprint(top_10_exp_21['Type'])\n\n51932    Patients with no prior ART using their own eggs\n54440    Patients with no prior ART using their own eggs\n54888    Patients with no prior ART using their own eggs\n57111    Patients with no prior ART using their own eggs\n59590                      Patients using their own eggs\n54008    Patients with no prior ART using their own eggs\n58797    Patients with no prior ART using their own eggs\n59709    Patients with no prior ART using their own eggs\n31781    Patients with no prior ART using their own eggs\n39719    Patients with no prior ART using their own eggs\nName: Type, dtype: object\n\n\n\nprint(top_10_exp_22['Type'])\n\n2979     Patients using donor eggs/embryos\n2974     Patients using donor eggs/embryos\n16477    Patients using donor eggs/embryos\n3015     Patients using donor eggs/embryos\n16482    Patients using donor eggs/embryos\n3010     Patients using donor eggs/embryos\n16513    Patients using donor eggs/embryos\n16518    Patients using donor eggs/embryos\n7967     Patients using donor eggs/embryos\n33694    Patients using donor eggs/embryos\nName: Type, dtype: object\n\n\n\nbottom_10_exp_20 = clean_20.nlargest(10, 'Expected # Cycles')\n\n\nbottom_10_exp_21 = clean_21.nlargest(10, 'Expected # Cycles')\n\n\nbottom_10_exp_22 = clean_22.nlargest(10, 'Expected # Cycles')\n\n\ntop_10_exp_20.head(1)\n\n\n\n\n\n\n\n\nYear\nLocationAbbr\nLocationDesc\nFacilityName\nMedicalDirector\nAddress\nCity\nZipCode\nPhone\nClinic Status\n...\nCycle_Count\nClinicId\nTypeId\nTopicId\nQuestionId\nFilterId\nBreakOutCategoryId\nBreakOutId\nGeoLocation\nExpected # Cycles\n\n\n\n\n14994\n2020\nIL\nIllinois\nAdvanced Fertility Center of Chicago\nMichelle Catenacci, MD\n30 Tower Ct, Suite F\nGurnee\n60031.0\n(847) 662-1818\nOpen\n...\n126.0\n300.0\nT001\nTOP04\nQ030\nF009\nCAT1\nB005\nPOINT (-87.8993371 42.3573697)\n1.05042\n\n\n\n\n1 rows × 30 columns\n\n\n\n\ntop_10_exp_21.head(1)\n\n\n\n\n\n\n\n\nYear\nLocationAbbr\nLocationDesc\nFacilityName\nMedicalDirector\nAddress\nCity\nZipCode\nPhone\nClinic Status\n...\nCycle_Count\nClinicId\nTypeId\nTopicId\nQuestionId\nFilterId\nBreakOutCategoryId\nBreakOutId\nGeoLocation\nExpected # Cycles\n\n\n\n\n51932\n2021\nIL\nIllinois\nAdvanced Fertility Center of Chicago\nMichelle Catenacci, MD\n30 Tower Ct, Suite F\nGurnee\n60031.0\n(847) 662-1818\nOpen\n...\n61.0\n300.0\nT003\nTOP03\nQ027\nF003\nCAT2\nB001\nPOINT (-87.8993 42.3574)\n1.075269\n\n\n\n\n1 rows × 30 columns\n\n\n\n\ntop_10_exp_22.head(1)\n\n\n\n\n\n\n\n\nYear\nLocationAbbr\nLocationDesc\nFacilityName\nMedicalDirector\nAddress\nCity\nZipCode\nPhone\nClinic Status\n...\nCycle_Count\nClinicId\nTypeId\nTopicId\nQuestionId\nFilterId\nBreakOutCategoryId\nBreakOutId\nGeoLocation\nExpected # Cycles\n\n\n\n\n2979\n2022\nCA\nCalifornia\nFertility Center of Southern California\nIlene E. Hatch, MD\n4980 Barranca Pkwy, Suite 200\nIrvine\n92604.0\n(949) 955-0072\nOpen\n...\n32.0\n211\nT001\nTOP04\nQ030\nF009\nCAT1\nB007\nPOINT (-117.794 33.6757)\n1.044932\n\n\n\n\n1 rows × 30 columns\n\n\n\n\nprint(bottom_10_exp_20['Type'])\n\n269          Patients using their own eggs\n302          Patients using their own eggs\n19021    Patients using donor eggs/embryos\n20984    Patients using donor eggs/embryos\n149          Patients using their own eggs\n8121     Patients using donor eggs/embryos\n14018    Patients using donor eggs/embryos\n227          Patients using their own eggs\n1547     Patients using donor eggs/embryos\n3748     Patients using donor eggs/embryos\nName: Type, dtype: object\n\n\n\nprint(bottom_10_exp_21['Type'])\n\n7737         Patients using their own eggs\n32317        Patients using their own eggs\n35831        Patients using their own eggs\n7208     Patients using donor eggs/embryos\n30161        Patients using their own eggs\n26405        Patients using their own eggs\n27474        Patients using their own eggs\n31113        Patients using their own eggs\n32815        Patients using their own eggs\n40355        Patients using their own eggs\nName: Type, dtype: object\n\n\n\nprint(bottom_10_exp_22['Type'])\n\n16748    Patients using donor eggs/embryos\n10290    Patients using donor eggs/embryos\n16753    Patients using donor eggs/embryos\n19527    Patients using donor eggs/embryos\n29995    Patients using donor eggs/embryos\n724      Patients using donor eggs/embryos\n7196     Patients using donor eggs/embryos\n10285    Patients using donor eggs/embryos\n5295     Patients using donor eggs/embryos\n19522    Patients using donor eggs/embryos\nName: Type, dtype: object\n\n\n\nprint(bottom_10_exp_20['Breakout'])\n\n269                           &gt;40\n302                           &gt;40\n19021              Frozen embryos\n20984    Fresh embryos fresh eggs\n149                           &lt;35\n8121               Frozen embryos\n14018              Frozen embryos\n227                         35-37\n1547               Frozen embryos\n3748               Frozen embryos\nName: Breakout, dtype: object\n\n\n\nprint(bottom_10_exp_21['Breakout'])\n\n7737                &gt;40\n32317               &gt;40\n35831               &gt;40\n7208     Frozen Embryos\n30161             38-40\n26405               &gt;40\n27474             38-40\n31113               &gt;40\n32815               &gt;40\n40355               &gt;40\nName: Breakout, dtype: object\n\n\n\nprint(bottom_10_exp_22['Breakout'])\n\n16748    Frozen Embryos\n10290    Frozen Embryos\n16753    Frozen Embryos\n19527    Frozen Embryos\n29995    Frozen Embryos\n724      Frozen Embryos\n7196     Frozen Embryos\n10285    Frozen Embryos\n5295     Frozen Embryos\n19522    Frozen Embryos\nName: Breakout, dtype: object\n\n\n\nprint(top_10_exp_20['LocationAbbr'].dropna())\n\n14994    IL\n7265     IL\n12958    IL\n12752    IL\n12700    IA\n13782    IL\n16176    IA\n13679    IL\n36053    CA\n35954    WA\nName: LocationAbbr, dtype: object\n\n\n\nprint(top_10_exp_21['LocationAbbr'].dropna())\n\n51932    IL\n54440    IL\n54888    IL\n57111    IA\n59590    IL\n54008    IL\n58797    IL\n59709    IL\n31781    CA\n39719    CA\nName: LocationAbbr, dtype: object\n\n\n\nprint(top_10_exp_22['LocationAbbr'].dropna())\n\n2979     CA\n2974     CA\n16477    MA\n3015     CA\n16482    MA\n3010     CA\n16513    MA\n16518    MA\n7967     CA\n33694    TX\nName: LocationAbbr, dtype: object\n\n\n\nprint(bottom_10_exp_20['LocationAbbr'].dropna())\n\n19021    NJ\n20984    MD\n149      MO\n8121     NV\n14018    NJ\n227      MI\n1547     NY\n3748     NY\nName: LocationAbbr, dtype: object\n\n\n\nprint(bottom_10_exp_21['LocationAbbr'].dropna())\n\n7737     NY\n32317    CO\n35831    CO\n7208     NY\n30161    CA\n26405    CA\n27474    CA\n31113    CO\n32815    CA\n40355    CO\nName: LocationAbbr, dtype: object\n\n\n\nprint(bottom_10_exp_22['LocationAbbr'].dropna())\n\n16748    MD\n10290    CO\n16753    MD\n19527    NJ\n29995    WA\n724      MA\n7196     CA\n10285    CO\n5295     GA\n19522    NJ\nName: LocationAbbr, dtype: object\n\n\n\nstate_order_20 = sorted(success_20_QF['LocationAbbr'].dropna().unique())\nstate_order_21 = sorted(success_21_QF['LocationAbbr'].dropna().unique())\nstate_order_22 = sorted(success_22_QF['LocationAbbr'].dropna().unique())\n\n\nprint(clean_20['Expected # Cycles'].dtype)\n\nfloat64\n\n\n\n\n\nsiz_clean_20 = clean_20[clean_20['Expected # Cycles'] &lt; 10]\nplt.figure(figsize = (12, 6))\nsns.boxplot(x = 'LocationAbbr', y = 'Expected # Cycles', data = siz_clean_20, order = state_order_20)\nplt.title('Expected # Cycles per Success by State 2020')\nplt.ylabel('Expected # of Cycles')\nplt.xlabel('State')\nplt.ylim(0, 10)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nsiz_clean_21 = clean_21[clean_21['Expected # Cycles'] &lt; 10]\nplt.figure(figsize = (12, 6))\nsns.boxplot(x = 'LocationAbbr', y = 'Expected # Cycles', data = siz_clean_21, order = state_order_21)\nplt.title('Expected # Cycles per Success by State 2021')\nplt.ylabel('Expected # of Cycles')\nplt.xlabel('State')\nplt.ylim(0,10)\nplt.show()\n#skewed distribution when ylim &gt; 150\n\n\n\n\n\n\n\n\n\n\n\nsiz_clean_22 = clean_22[clean_22['Expected # Cycles'] &lt; 10]\nplt.figure(figsize = (12, 6))\nsns.boxplot(x = 'LocationAbbr', y = 'Expected # Cycles', data = siz_clean_22, order = state_order_21)\nplt.title('Expected # Cycles per Success by State 2022')\nplt.ylabel('Expected # of Cycles')\nplt.xlabel('State')\nplt.ylim(0,10)\nplt.show()\n\n\n\n\n\n\n\n\n\nnum_cycles_20 = success_20['Cycle_Count'].sum()\nnum_cycles_21 = success_21['Cycle_Count'].sum()\nnum_cycles_22 = success_22['Cycle_Count'].sum()\nprint(num_cycles_20)\nprint(num_cycles_21)\nprint(num_cycles_22)\n\n3252883.0\n2514131.0\n7228336.0\n\n\n\nsucc_combined = pd.concat([success_20, success_21, success_22], ignore_index = True)\n\nsummary_region_yr_cyc = succ_combined.groupby(['Year'])['Cycle_Count'].sum().reset_index()\n\n\nplt.figure(figsize=(10, 6))\nsns.lineplot(data = summary_region_yr_cyc, x = 'Year', y = 'Cycle_Count')\nplt.title('# Cycles per year (2020-2022)')\nplt.ylabel('# Cycles')\nplt.xticks([2020, 2021, 2022])\n\nplt.show()\n\n\n\n\n\n\n\n\n\nstate_means_20 = clean_20.groupby('LocationAbbr')['Expected # Cycles'].mean()\nstate_means_21 = clean_21.groupby('LocationAbbr')['Expected # Cycles'].mean()\nstate_means_22 = clean_22.groupby('LocationAbbr')['Expected # Cycles'].mean()\n\nmax_state_20 = state_means_20.idxmin()\nmax_state_val_20 = state_means_20.min()\nmax_state_21 = state_means_21.idxmin()\nmax_state_val_21 = state_means_21.min()\nmax_state_22 = state_means_22.idxmin()\nmax_state_val_22 = state_means_22.min()\n\nprint(max_state_20, max_state_val_20)\nprint(max_state_21, max_state_val_21)\nprint(max_state_22, max_state_val_22)\n\nyears_ = [2020, 2021, 2022]\nmin_vals = [max_state_20, max_state_21, max_state_22]\n\n\n\nKS 2.458242544449441\nMS 1.7844408221480785\nKY 2.886002886002886\n\n\n\nKS_mean = clean_20[clean_20['LocationAbbr'] == 'KS']\nMS_mean = clean_21[clean_21['LocationAbbr'] == 'MS']\nKY_mean = clean_22[clean_22['LocationAbbr'] == 'KY']\n\n\nKS_type_mean = KS_mean.groupby('Type')['Expected # Cycles'].mean()\nMS_type_mean = MS_mean.groupby('Type')['Expected # Cycles'].mean()\nKY_type_mean = KY_mean.groupby('Type')['Expected # Cycles'].mean()\n\nKS_type_20 = KS_type_mean.idxmin()\nKS_val_20 = KS_type_mean.min()\nMS_type_21 = MS_type_mean.idxmin()\nMS_val_21 = MS_type_mean.min()\nKY_type_22 = KY_type_mean.idxmin()\nKY_val_22 = KY_type_mean.min()\n\nprint(KS_type_20, KS_val_20)\nprint(MS_type_21, MS_val_21)\nprint(KY_type_22, KY_val_22)\n\nPatients using donor eggs/embryos 2.458242544449441\nPatients using their own eggs 1.7844408221480785\nPatients using donor eggs/embryos 2.886002886002886\n\n\n\nKS_breakout = KS_mean.groupby('Breakout')['Expected # Cycles'].mean()\nMS_breakout = MS_mean.groupby('Breakout')['Expected # Cycles'].mean()\nKY_breakout = KY_mean.groupby('Breakout')['Expected # Cycles'].mean()\n\nmax_break_KS = KS_breakout.idxmin()\nmax_break_val_KS = KS_breakout.min()\nmax_break_MS = MS_breakout.idxmin()\nmax_break_val_MS = KS_breakout.min()\nmax_break_KY = KS_breakout.idxmin()\nmax_break_val_KY = KY_breakout.min()\n\nprint(max_break_KS, max_break_val_KS)\nprint(max_break_MS, max_break_val_MS)\nprint(max_break_KY, max_break_val_KY)\n\nFrozen embryos 2.2137823861961796\n&lt;35 2.2137823861961796\nFrozen embryos 2.886002886002886\n\n\n\ntype_means_20 = clean_20.groupby('Type')['Expected # Cycles'].mean()\ntype_means_21 = clean_21.groupby('Type')['Expected # Cycles'].mean()\ntype_means_22 = clean_22.groupby('Type')['Expected # Cycles'].mean()\n\nmax_type_20 = type_means_20.idxmin()\nmax_type_val_20 = type_means_20.min()\nmax_type_21 = type_means_21.idxmin()\nmax_type_val_21 = type_means_21.min()\nmax_type_22 = type_means_22.idxmin()\nmax_type_val_22 = type_means_22.min()\n\nprint(max_type_20, max_type_val_20)\nprint(max_type_21, max_type_val_21)\nprint(max_type_22, max_type_val_22)\nprint('Avg =',((max_type_val_20 + max_type_val_21 + max_type_val_22)/3))\n\nPatients with no prior ART using their own eggs 2.48195914815552\nPatients with no prior ART using their own eggs 4.032826609073903\nPatients with no prior ART using their own eggs 4.34949686263115\nAvg = 3.6214275399535247\n\n\n\nbreakout_means_20 = clean_20.groupby('Breakout')['Expected # Cycles'].mean()\nbreakout_means_21 = clean_21.groupby('Breakout')['Expected # Cycles'].mean()\nbreakout_means_22 = clean_22.groupby('Breakout')['Expected # Cycles'].mean()\n\nmax_breakout_20 = breakout_means_20.idxmin()\nmax_breakout_val_20 = breakout_means_20.min()\nmax_breakout_21 = breakout_means_21.idxmin()\nmax_breakout_val_21 = breakout_means_21.min()\nmax_breakout_22 = breakout_means_22.idxmin()\nmax_breakout_val_22 = breakout_means_22.min()\n\nprint(max_breakout_20, max_breakout_val_20)\nprint(max_breakout_21, max_breakout_val_21)\nprint(max_breakout_22, max_breakout_val_22)\n\nFresh embryos frozen eggs 5.642031674459756\nDonated Embryos 5.909250494757963\n&lt;35 2.15405643785669"
  },
  {
    "objectID": "src/about.html",
    "href": "src/about.html",
    "title": "About",
    "section": "",
    "text": "My name is Joseph, a Senior Applied Computer Science student at CU Boulder with a focus in Data Science. Specifically I am drawn to medical/health-related data projects and aspire to influence positive change for the community at large with my work. I enjoy challenging problems that require creativity and technical skills to solve. My goal is to transition from a frontline health care worker to affecting change at a larger scale with analytical contributions"
  },
  {
    "objectID": "src/contact.html",
    "href": "src/contact.html",
    "title": "Contact Information",
    "section": "",
    "text": "Email: jhook1173@gmail.com\nGitHub: https://github.com/JHook1227/Portfolio.git\nLocation: Kansas City, Kansas\n(for the purposes of this course I don’t want to put a lot of PII on thie website)"
  },
  {
    "objectID": "src/index.html",
    "href": "src/index.html",
    "title": "Portfolio: Joseph Hook",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "src/resume.html",
    "href": "src/resume.html",
    "title": "Resume",
    "section": "",
    "text": "Electrophysiology Technologist II | KUMC – Kansas City, KS\n\n\nSep 2023 – Present\n• Facilitated electrophysiology (EP) studies by analyzing intracardiac EGMs and executing cardiac stimulation protocols to identify arrhythmias\n• Served as scrub technologist for ablation and device procedures, supporting physicians in safe and effective patient care\n• Setup cardiac mapping systems: CARTO, Affera, Opal, Ensite X, Ensite Precision\n• Troubleshot catheter and mapping system issues such as pinning errors, connection failures, and equipment malfunctions—to ensure uninterrupted procedural workflow\n\n\nExercise Physiologist | HCA – Denver, CO\n\n\nDecember 2021 – Sep 2023\n• Created custom exercise plans to meet the needs of patients in coordination with Physical, Occupational and Speech Therapists to execute the individualized plan of care.\n• Educated patients on exercise programs and created appropriate Home Exercise Program when patients are discharged.\n• Operated and managed the EKSO bionic exoskeleton program in tandem with Physical Therapists.\n• Maintained treatment areas, exercise equipment, as well as DME ordering.\n\n\nFlight Chief | United States Air Force – May 2012 – May 2019\n● Acted as on-scene commander for emergency crises by establishing secure areas and coordinating emergency responses.\n● Enforced security protocols which included Random Anti-Terrorism Measures and in-depth alarm notification systems.\n● Efficiently managed a diverse workforce and training program to ensure subordinates were prepared for their duties.\n● Managed security clearance certification program by conducting background investigations."
  }
]